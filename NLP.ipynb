{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP\n",
    "Natural language processing (NLP) is a subfield of computer science and artificial intelligence (AI) that uses machine learning to enable computers to understand and communicate with human language."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.prod.website-files.com/5ec6a20095cdf182f108f666/5f22908f09f2341721cd8901_AI%20poster.png\" width=\"40%\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why it is needed?\n",
    "\n",
    "Natural Language Processing (NLP) is essential because it bridges the gap between human communication and machine understanding, enabling computers to process and analyze human language effectively. Here are the key reasons why NLP is needed, along with examples:\n",
    "\n",
    "**1. Understanding Human Language**<br>\n",
    "Computers inherently do not understand human languages, which are complex, context-dependent, and full of nuances like sarcasm, idioms, and dialects. NLP enables machines to interpret and generate human language for meaningful interaction.<br>\n",
    "**e.g.,** Virtual assistants like Alexa and Siri use NLP to interpret spoken commands and provide relevant responses.\n",
    "\n",
    "**2. Automating Repetitive Tasks**<br>\n",
    "NLP automates tasks such as data entry, document classification, and summarization, saving time and reducing errors.<br>\n",
    "**e.g.,** Customer service chatbots handle routine queries, freeing human agents for complex issues.\n",
    "\n",
    "**3. Analyzing Unstructured Data**<br>\n",
    "A significant portion of data is unstructured (e.g., social media posts, reviews). NLP extracts insights from this data for decision-making.<br>\n",
    "**e.g.,** Sentiment analysis helps businesses understand customer opinions from reviews or tweets.\n",
    "\n",
    "**4. Enhancing Productivity**<br>\n",
    "NLP-powered tools streamline workflows by automating tasks like email sorting, invoice processing, or extracting key information from documents.<br>\n",
    "**e.g.,** Accounting systems use NLP to populate databases from invoices automatically.\n",
    "\n",
    "**5. Enabling Accessibility**<br>\n",
    "NLP makes technology accessible to people with disabilities by supporting voice commands and text-to-speech systems.<br>\n",
    "**e.g.,** Screen readers for visually impaired users leverage NLP for better comprehension.\n",
    "\n",
    "**6. Improving Communication Across Languages**<br>\n",
    "NLP facilitates real-time language translation, breaking down communication barriers globally.<br>\n",
    "**e.g.,** Google Translate uses NLP to translate text while preserving meaning and context.\n",
    "\n",
    "**7. Driving Innovation in Specialized Fields**<br>\n",
    "NLP enables advancements in fields like healthcare (analyzing medical records) or autonomous systems (interpreting commands).<br>\n",
    "**e.g.,** Clinical applications use NLP to summarize patient records efficiently.\n",
    "\n",
    "**8. Knowledge Graph and QA systems**<br>\n",
    "A knowledge graph (KG) is a structured network of entities (nodes) and their relationships (edges) that enables machines to understand context and meaning, making it a critical component in modern question-answering (QA) systems.<br>\n",
    "**e.g.** When asked, \"Where was the painter of the Mona Lisa born?\", the KG links \"Mona Lisa\" ‚Üí \"painted by\" ‚Üí \"Leonardo da Vinci\" ‚Üí \"born in\" ‚Üí \"Italy\" to derive the answer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://assets.zilliz.com/Figure_1_Knowledge_graphs_illustration_643cec06af.png\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " For example, a search for the film director James Cameron reveals information such as his date of birth, height, movies and TV shows he directed, previous romantic partners, TED Talks he gave\n",
    "\n",
    " **9. Text parsing**<br>\n",
    "Text parsing, also known as syntactic analysis, is the process of analyzing text to understand its structure and meaning based on grammatical rules, separating it into smaller components for further processing. \n",
    "\n",
    "<img src='https://cdn.botpenguin.com/assets/website/Parsing_4bcdfead23.webp' width='40%'></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approaches used for NLP\n",
    "**1. Heuristic approach**<br>\n",
    "Heuristics are mental shortcuts that allow people to solve problems and make judgments quickly and efficiently.\n",
    "\n",
    "e.g., use of Regular expressions, wordnet, open mind common sense.\n",
    "\n",
    "**2. ML approach**<br>\n",
    "Based on data. We convert the text into numbers and then apply algorithms.\n",
    "\n",
    "e.g., Naive bayes, SVM, Logistic regression, LDA, Hidden markov models\n",
    "\n",
    "**3. Deep Learning Approach**<br>\n",
    "In ML, sequential information is lost when text converted into numbers. In DL, the sequential information is preserved and also no feature generation is needed in DL unlike ML.\n",
    "\n",
    "e.g., RNN, LSTM, GRU, Transformers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challanges in NLP\n",
    "\n",
    "**1. Ambiguity**<br>\n",
    "So much meaning of a single word or sentence is easy for us but not for machines.\n",
    "\n",
    "e.g., I saw the boy on the bench with my binoculars.\n",
    "\n",
    "**2. Contextual word**<br>\n",
    "Different meaning of the word based on the context.\n",
    "\n",
    "e.g., I ran to the store because we ran out of the supplies.\n",
    "\n",
    "**3. Colloquialisms and Slangs**<br>\n",
    "pulling leg meaning is different in our context but not for machines. Colloquialisms are a word or phrase that is used in conversation but not in formal speech or writing\n",
    "\n",
    "**4. Synonyms**\n",
    "\n",
    "**5. Tonal difference and irony**\n",
    "\n",
    "**6. Speeling errors**\n",
    "\n",
    "**7. Creativity**<br>\n",
    "e.g., Poems, dialogs, scripts\n",
    "\n",
    "**8. So much languages/ diversity**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP Pipeline\n",
    "Steps followed to build an end to end NLP software. It consists of following steps:\n",
    "\n",
    "1. Data acquisition\n",
    "\n",
    "2. Text Preparation: \n",
    "    - Text cleanup <br>(like spelling mistakes or emoji removing etc.), \n",
    "    - Basic preprocessing <br>(removing punctuations, stopwords and tokenization etc.) \n",
    "    - Advance preprocessing <br>(chunking, Parts-of-speech or POS tagging, co-reference resolution etc.)\n",
    "\n",
    "3. Feature Engineering:<br>\n",
    "Converting words into numbers. <br>\n",
    "e.g., TF-IDF, Bag-of-words, word2vec\n",
    "\n",
    "4. Modelling\n",
    "    - Model building\n",
    "    - evaluation\n",
    "\n",
    "5. Deployment\n",
    "    - Deployment\n",
    "    - Monitoring\n",
    "    - Model update\n",
    "\n",
    "This pipeline is mainly for ML, not for DL. Also this is not universal, e.g., this pipeline is good for sentiment analysis or text summarization but not chatbot.\n",
    "\n",
    "Also, this is non-linear, i.e., we go back n forth continously depending on the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```mermaid\n",
    "---\n",
    "title: \"1. Data Acquisition\"\n",
    "---\n",
    "%%{init: {\"flowchart\": {\"htmlLabels\": true}}}%%\n",
    "flowchart LR\n",
    "\n",
    "    A{\"<b>Data Acquisition</b>\"} --> B(\"Available\") & C(\"Other Sources\") & D(\"No where\")\n",
    "    subgraph Available[\" \"]\n",
    "        B --> E[\"Already available in csv\"] & F[\"In the data warehouse, \\nneed a data engineer to retrieve the data\"] & G[\"Less Data\"]\n",
    "        G --> H[\"Data \\naugmentation\"]\n",
    "        H --> HA[\"Replacing some words with Synonyms\"] & HB[\"Bigram flip | e.g., [king, man] to [man, king]\"] & HC[\"Back-translate \\n| Used to rearrange text \\n| Converting into another lang & \\nthen converting back\"] & HD[\"Adding Noise\"]\n",
    "    end\n",
    "    style A color:#000000, fill:#FFF9C4,  stroke:#000000\n",
    "\n",
    "    subgraph OtherSources[\" \"]\n",
    "        C --> CA[\"<p align='left'>1. Public Dataset <br> 2. Web Scraping <br> 3. APIs <br> 4. PDF <br> 5. Image <br> 6. Audio\"] \n",
    "    end\n",
    "\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```mermaid\n",
    "---\n",
    "title: 2. Text preparation\n",
    "---\n",
    "%%{init: {\"flowchart\": {\"htmlLabels\": true}}}%%\n",
    "flowchart LR\n",
    "\n",
    "    A{\"<b>Text Preparation</b>\"} --> B(Cleaning) & C(Basic preprocessing) & D(Advance Preprocessing)\n",
    "    subgraph Basic_preprocessing[\" \"]\n",
    "    C --> CA[Must] & CC[\"Optional \\n|Based on application\"]\n",
    "    CA --> CAA[\"Tokenization \\n| Sentence or Word Tokenization\"]\n",
    "    CC --> CCA[\"<p align='left'>1. StopWords removal \\n2. Word Stemming \\n3. Removing Digits & punctuation \\n4. Lower casing \\n5. Language Detection\"]\n",
    "    end\n",
    "    subgraph Advance_preprocessing[\" \"]\n",
    "    D --> DA[\"<p align='left'>1. POS tagging\\n2. Parsing\\n3. Corefence resolution\"]\n",
    "    end\n",
    "\n",
    "style A color:#000000, fill:#FFF9C4,  stroke:#000000\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```mermaid\n",
    "flowchart TB\n",
    "A{\"<b>modeling</b>\"} --> B[\"Heuristic approach \\n (if less data)\"] & C[\"ML Models\\n (if thik-thak data)\"] & D[\"DL\\n (if much data)\"] & E[\"Cloud API \\n (if andha paisa)\"]\n",
    "style A color:#000000, fill:#FFF9C4,  stroke:#000000\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove html tags\n",
    "import re\n",
    "def remove_html(data):\n",
    "    p = re.compile(r'<.*?>')\n",
    "    return p.sub(r'', data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Krishna..  yes'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = \"<html><head>Krishna.. <a href='google.com'> yes\"\n",
    "remove_html(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Why remove punctuations?\n",
    "Punctuation removal simplifies text data, streamlining the analysis by reducing the complexity and variability within the data. Also punctuation does't have exact meaning.\n",
    "\n",
    "e.g., `hi!` and `hi` will be treated differently and will increase complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punc(text):\n",
    "    for char in string.punctuation:\n",
    "        text = text.replace(char, '')\n",
    "    return text\n",
    "text = r\"\"\"Removing stopwords is a common text-processing task. The words (like \"is,\" \"the,\" \"at,\" etc.) usually don't contribute to the meaning\"\"\"\n",
    "remove_punc(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0002079010009765625\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "remove_punc(text)\n",
    "time1 = time.time() - start\n",
    "print(time1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OR\n",
    "import string\n",
    "def again_punc_remove(text):\n",
    "    return text.translate(str.maketrans('', '', string.punctuation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00016546249389648438\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "again_punc_remove(text)\n",
    "time2 = time.time() - start\n",
    "print(time2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spell correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrect = \"wjo iss thiis? worng speeling \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'who iss this? wrong spelling '"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TextBlob(incorrect).correct().string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/naman/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'emoji'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n",
      "\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01memoji\u001b[39;00m\n",
      "\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'emoji'"
     ]
    }
   ],
   "source": [
    "import emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " \"he'd\",\n",
       " \"he'll\",\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " \"he's\",\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " \"i'd\",\n",
       " 'if',\n",
       " \"i'll\",\n",
       " \"i'm\",\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it'd\",\n",
       " \"it'll\",\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " \"i've\",\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she'd\",\n",
       " \"she'll\",\n",
       " \"she's\",\n",
       " 'should',\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " \"should've\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " \"they'd\",\n",
       " \"they'll\",\n",
       " \"they're\",\n",
       " \"they've\",\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " \"we'd\",\n",
       " \"we'll\",\n",
       " \"we're\",\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " \"we've\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " 'your',\n",
       " \"you're\",\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " \"you've\"]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python is  :grinning_face::grinning_face_with_big_eyes::grinning_face_with_smiling_eyes::beaming_face_with_smiling_eyes::grinning_squinting_face:\n"
     ]
    }
   ],
   "source": [
    "import emoji\n",
    "print(emoji.demojize('''Python is  üòÄüòÉüòÑüòÅüòÜ'''))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
